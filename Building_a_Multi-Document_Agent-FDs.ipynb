{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6507d9d4-bf4d-44d9-82df-fe560c859b2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Core deps\n",
    "%pip install -qqq python-dotenv llama-index openai\n",
    "# Optional embedding + doc processing\n",
    "%pip install -qqq llama-index-embeddings-openai torch transformers\n",
    "# Vector store\n",
    "%pip install -qqq llama-index-vector-stores-chroma docx2txt python-pptx Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f7da344-e652-4e06-943e-bc54f771de20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7a8df73-31dc-4455-90cd-5f82f10d77bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from dotenv import load_dotenv\n",
    "import mlflow\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "mlflow.autolog(disable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b74485d-3052-4d34-ae34-18376b27b66b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "RAG_FILES_DIRECTORY= \"/Volumes/development/fiaa_qa/rag_data/sample\"\n",
    "CHRONOS_DB = \"./chronos_db\"\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d2e27f3-e62f-45d7-a399-e838a6446a17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9e49f45-54f8-4cb7-8a45-24e2b6b9abef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Configure LLM Details\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import Settings\n",
    "embed_model = OpenAIEmbedding(model=\"text-embedding-ada-002\")\n",
    "Settings.embed_model=embed_model\n",
    "from llama_index.llms.openai import OpenAI\n",
    "llm = OpenAI(model='gpt-3.5-turbo')\n",
    "print(f\"Current embedding model: {Settings.embed_model}\")\n",
    "print(f\"Current chat model: {Settings.llm.model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ebc6c4c6-6268-4df6-9b4d-1a8804139688",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import chromadb\n",
    "import pickle\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "\n",
    "db = chromadb.PersistentClient(path= \"./chronos_db/\")\n",
    "chroma_collection = db.get_or_create_collection(\"otc_fds\")\n",
    "persist_directory = \"./chronos_db/\"\n",
    "vector_store = ChromaVectorStore( chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae9f88b2-ce65-4dfd-be27-3629adb8487b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, SummaryIndex\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.tools import QueryEngineTool, FunctionTool\n",
    "from llama_index.core.vector_stores import MetadataFilters, FilterCondition\n",
    "from typing import List, Optional\n",
    "import re, pickle\n",
    "\n",
    "def sanitize_name(name: str) -> str:\n",
    "    '''Sanitize the name to match the expected pattern'''\n",
    "    return re.sub(r'[^a-zA-Z0-9_-]', '_', name)\n",
    "\n",
    "def get_doc_tools(\n",
    "    file_path:str,\n",
    "    name: str\n",
    ")-> str:\n",
    "    '''Get Vector query and summary query tools from a document'''\n",
    "    \n",
    "    \n",
    "    documents = SimpleDirectoryReader(input_files=[file_path]).load_data()\n",
    "    # proccessed_documents = [handle_surrogates(doc.text) for doc in documents]\n",
    "    splitter = SentenceSplitter(chunk_size=1024)\n",
    "    nodes = splitter.get_nodes_from_documents(documents)\n",
    "    vector_index = VectorStoreIndex(nodes, storage_context=storage_context)\n",
    "    name = sanitize_name(name)\n",
    "    \n",
    "    def vector_query(query:str,\n",
    "                     page_number:Optional[List[str]] = None\n",
    "                     )->str:\n",
    "        \"\"\"Use to answer questions over a given paper.\n",
    "    \n",
    "        Useful if you have specific questions over the paper.\n",
    "        Always leave page_numbers as None UNLESS there is a specific page you want to search for.\n",
    "    \n",
    "        Args:\n",
    "            query (str): the string query to be embedded.\n",
    "            page_numbers (Optional[List[str]]): Filter by set of pages. Leave as NONE \n",
    "                if we want to perform a vector search\n",
    "                over all pages. Otherwise, filter by the set of specified pages.\n",
    "        \n",
    "        \"\"\"\n",
    "        page_numbers = page_numbers or [None]\n",
    "        metadata_dicts=[\n",
    "            {\"key\":\"page_label\", \"value\": page_number} for page_number in page_numbers\n",
    "\n",
    "        ]\n",
    "        query_engine = vector_index.as_query_engine(\n",
    "            similarity_top_k=2,\n",
    "            filters=MetadataFilters.from_dicts(\n",
    "                metadata_dicts,\n",
    "                condition = FilterCondition.OR\n",
    "           )\n",
    "        )\n",
    "        response = query_engine.query(query)\n",
    "        return response\n",
    "        \n",
    "    vector_query_tool = FunctionTool.from_defaults(\n",
    "        name=f'vector_tool_{name}',\n",
    "        fn=vector_query,\n",
    "    )\n",
    "    summary_index = SummaryIndex(nodes, storage_context=storage_context)\n",
    "    summary_query_engine = summary_index.as_query_engine(\n",
    "        response_mode=\"tree_summarize\",\n",
    "        use_async=True\n",
    "    )\n",
    "    summary_tool = QueryEngineTool.from_defaults(\n",
    "        name=f'summary_tool_{name}',\n",
    "        query_engine=summary_query_engine,\n",
    "        description=(f'Useful for summarization questions related to {name}')\n",
    "        )\n",
    "    # Save VectorStoreIndex to a file\n",
    "    with open('vector_index.pkl', 'wb') as f:\n",
    "        pickle.dump(vector_index, f)\n",
    "\n",
    "    # Save SummaryIndex to a file\n",
    "    with open('summary_index.pkl', 'wb') as f:\n",
    "        pickle.dump(summary_index, f)\n",
    "        \n",
    "    return vector_query_tool, summary_tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28511298-e1e5-4b48-b502-77ff4c68aa59",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_tools_from_directory(directory_path: str):\n",
    "    all_tools = []\n",
    "    directory  = Path(directory_path)\n",
    "    for file_path in directory.glob(\"*\"):\n",
    "        name = file_path.stem\n",
    "        print (f'Getting tools for paper : {name}')\n",
    "        vector_tool, summary_tool = get_doc_tools(file_path, name)\n",
    "        all_tools.extend([vector_tool, summary_tool])\n",
    "    return all_tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "cffbe867-ea87-42f8-b547-a4bb1284a8d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pathlib  import Path\n",
    "directory = RAG_FILES_DIRECTORY\n",
    "tools_list = create_tools_from_directory(directory)\n",
    "print (tools_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "697c34cb-a24e-449c-b13f-374b7557351e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print (tools_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a24f264-77d4-483d-b2d6-1741e2ba00f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.objects import ObjectIndex\n",
    "\n",
    "obj_index = ObjectIndex.from_objects(\n",
    "    tools_list,\n",
    "    index_cls=VectorStoreIndex,\n",
    "    storage_context=storage_context\n",
    "    )\n",
    "# Save ObjectIndex to a file\n",
    "with open('obj_index.pkl', 'wb') as f:\n",
    "    pickle.dump(obj_index, f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "589894f7-09ad-4879-aa3b-4f53ea608aa8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e142f2d0-8588-4ce5-814f-8f72042ac5df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create the ObjectIndex\n",
    "print (obj_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1031a4c-835b-421c-9524-fabce8879716",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "obj_retreiver = obj_index.as_retriever(similarity_top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67e52168-a14a-4f6f-8ab8-9b475eed6928",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tools = obj_retreiver.retrieve(\"Tell me about FOH\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "579adbd7-3f54-4eb9-a267-0721be44605f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tools[1].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92f787e9-ec60-4fa9-9fb1-ecaabced30a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from llama_index.core.agent import FunctionCallingAgentWorker, AgentRunner\n",
    "\n",
    "agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "    llm=llm,\n",
    "    tool_retriever=obj_retreiver,\n",
    "    system_prompt=\"\"\" \\\n",
    "You are an agent designed to answer queries over a set of given papers.\n",
    "Please always use the tools provided to answer a question. Do not rely on prior knowledge.\\\n",
    "\n",
    "\"\"\",\n",
    "verbose=True)\n",
    "agent = AgentRunner(agent_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d676ccb-4d87-4f3b-af8c-7a857ad6c481",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "response = agent.query(\n",
    "    \"Tell me about FOH\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cb34f9e-863b-4265-86b6-2e0c2ea81788",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print (str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76359a06-e2e0-41c2-875a-60f51b20f0ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Building_a_Multi-Document_Agent-FDs",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
